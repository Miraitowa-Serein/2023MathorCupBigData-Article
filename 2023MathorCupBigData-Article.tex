% !TeX program = xelatex
% !TeX encoding = UTF-8
\documentclass{MathorCupmodeling}
\usepackage{mwe,color,float}
\usepackage[linesnumbered,ruled]{algorithm2e}
\usepackage{setspace}
\usepackage{pdfpages}
\usepackage{graphicx}
\extrafloats{100}
\bianhao{MCB2301959}
\tihao{A}
\timu{\textbf{基于卷积神经网络图像特征提取的SVM坑洼道路检测与识别}}
\keyword{特征工程；计算机视觉；支持向量机；评分预测；可视化评估}
\begin{document}
	\begin{abstract}
		{\heiti 最后}，本文对所建立的模型的优缺点进行了中肯的评价、提出了模型的改进措施以及对模型进行了一定推广。
	\end{abstract}

	\pagestyle{empty}
	\tableofcontents
	\newpage
	\pagestyle{fancy}

	\setcounter{page}{1}
	\section{问题的提出}
	\subsection{问题背景}
	坑洼道路的检测与识别工作是推动自动无人驾驶、地质勘探、航天科学及自然灾害等领域研究和应用的不可或缺的计算机视觉任务。然而传统的分类算法往往因坑洼图像的复杂及多变性，不能取得较好的效果。近年来，深度学习邻域技术的发展为坑洼道路的检测、为当前存在的亟待解决的问题提供了新的思想。

	在实际工程应用中，非结构化的坑洼道路检测将遇到复杂多样的环境，例如，道路周围环境存在差异、光照条件变化等，这无疑增加了基于视觉检测道路的难度\textcolor{blue}{\cite{曹江华}}。道路坑洼的检测是实现智能车辆导航的基础，只有快速准确地检测出道路的可行驶区域才能够真正实现自动驾驶。

	深度学习拥有很强的特征提取与表示能力，可从图像中提取重要特征。于坑洼道路检测和识别而言，其可识别坑洼的轮廓、纹理、形态等特征，并将上述特征转换为更易分类的表现形式。在深度学习的基础上，迁移学习、知识蒸馏等技术可进一步提升分类性能以更加准确对新出现的道路图像自动识别。
	\subsection{问题要求}
	\begin{itemize}
		\item \textbf{问题一：}基于图像文件，提取图像特征，以“正常”和“坑洼”为特征建立一个识别率高、速度快且分类准确的模型。
		\item \textbf{问题二：}对问题一中所建立的模型进行训练，并对其进行多维度的评估分析。
		\item \textbf{问题三：}利用训练模型识别测试集中的坑洼图像，并展分析结果的合理性。
	\end{itemize}
	\section{问题的分析}
	\subsection{问题的整体分析}
	该题是一个基于计算机视觉的坑洼道路的图像数据分析、预测类问题。

	\textbf{从分析目的看}，本题需要分析道路图像并提取其特征，并建立一个识别率高、速度快、分类准确的模型，用以准确判断道路是正常或是坑洼。因此本题需要完成以下两方面任务：{\heiti 其一}，分析、研究不同道路图像的特征并归类总结。{\heiti 其二}，根据上述分析，建立合适的模型，通过对道路图像特征识别，判断道路是否正常。确保模型的准确性、快速性及普适性。

	\textbf{从图像数据特征看}，本题的道路图像具有数量多，环境等情况复杂，以及坑洼形态多样等特征，极大地增加的模型学习的难度。

	\textbf{从模型的选择看}，本题图像数量多，特征复杂，且需要对道路图像做出准确分类。同时结合图像数据特征的分析，我们考虑结合图像增强技术建立深度学习的特征提取与分类的机器学习模型。

	\textbf{从编程软件的选择看}，本题为图像大数据分析类，需要对大量的图片数据进行分析，并依据设问建立合适的模型，对正常及坑洼道路的图像进行分类预测，因此我们选择使用Python Jupyter对问题进行求解，其交互式的编程范式及轻量化，方便且高效。

	\subsection{各问题逐一分析}
	\begin{itemize}
		\item \textbf{问题一}：其核心目的在于结合给定的图像数据集，对其进行特征的提取，从而建立一个用于识别其为正常道路或是坑洼道路的模型。此外，该模型需要具有识别率高、速度快、分类准确的特点。
		\item \textbf{问题二}：其核心目的在于对问题一的模型进行训练，并对其进行多维度的评估分析，以保证模型的准确性、快速性及普适性。
		\item \textbf{问题三}：其核心目的在于利用上述已建立的模型，对未知数据集图像进行分类，并保存结果。
	\end{itemize}
	\section{符号说明}
	\begin{center}
		\scalebox{0.92}{
		\begin{tabularx}{0.7\textwidth}{c@{\hspace{1pc}}|@{\hspace{2pc}}X}
			\Xhline{0.08em}
			符号 & \multicolumn{1}{c}{符号说明}\\
			\Xhline{0.05em}
			$\mu$ & 样本平均值\\
			$\sigma$ & 样本方差\\
			$x_{\mathrm{standard}}$ & 经过标准化后的数据\\
			$R\left(x\right)_{m\times n}$ & 经过某项处理后的数据特征集\\
			$\rho$ & 皮尔逊相关系数\\
			$x'$ & 经过某项处理后的数据\\
			$Gini$ & 样本集合基尼系数\\
			$\hat{y}$ & 预测值\\
			$L^{\left(t\right)}$ & 目标函数\\
			$\Omega$ & 叶节点正则项惩罚系数\\
			$P$ & 某事件发生的概率\\
			$\omega$ & 权重\\
			\Xhline{0.08em}
		\end{tabularx}}
	\end{center}
	\section{模型的假设}
	本文对于模型的假设与初赛假设一致，如下：
	\begin{itemize}
		\item \textbf{假设一}：语音与上网业务的八项评分中，存在个别用户乱评、错评现象；
		\item \textbf{假设二}：除个别用户的部分评分外，其余所有数据真实且符合实际情况；
		\item \textbf{假设三}：用户评分还受到除附件中因素之外的因素的影响；
		\item \textbf{假设四}：给定的数据集可全面体现用户整体情况；
		\item \textbf{假设五}：对于同一业务，学习数据与预测数据的内在规律是一致的。
	\end{itemize}
	\section{模型的建立与求解}
	\subsection{图像文件预处理}\label{图像文件预处理}
	该题附件1为“data.zip”，共包含301张图片，且均为“jpg”格式，且在文件名中进行了标注。其中，文件名中包含“normal”字符的表示正常道路，共266张，包含“potholes”字符的为坑洼道路，共35张。考虑到数据的标注严谨性，我们首先对其进行人为再分类，将标注异常的进行重新标注或剔除。此外，为方便后续模型的分析、建立与求解，我们将“normal”与“potholes”图像文件置于“DATA”文件下的“normal”及“potholes”文件夹中。
	\subsubsection{人为再分类}
	考虑到数据的标注严谨性，我们首先对其进行人为再分类，将标注异常的进行重新标注或剔除。对于所给数据集，我们筛选出了以下几张图片，其标注存在问题，需要进行重新标注或剔除，如\textcolor{blue}{\cref{fig:异常图片}}所示，图中所标注的为该图像的原始文件名。
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.8]{异常图片.pdf}
		\caption{标注异常图片}
		\label{fig:异常图片}
	\end{figure}

	对于上述“(e) normal298.jpg”文件，我们选择剔除，其余划分为“potholes”类。具体处理见\textcolor{blue}{\cref{tab:异常图片处理}}。

\begin{table}[H]
	\centering
	\caption{异常标注图片的处理}
	\scalebox{0.9}{
	  \begin{tabular}{ccc}
	  \toprule
	  \textbf{编号}    & \textbf{原文件名}  & \textbf{处理方式} \\
	  \midrule
	  a     & normal9.jpg & potholes \\
	  b     & normal106.jpg & potholes \\
	  c     & normal173.jpg & potholes \\
	  d     & normal240.jpg & potholes \\
	  e     & normal298.jpg & 删除 \\
	  f     & normal312.jpg & potholes \\
	  g     & normal346.jpg & potholes \\
	  \bottomrule
	  \end{tabular}}
	\label{tab:异常图片处理}
\end{table}
	\subsubsection{文件夹分类}
	为了后续模型的分析、建立与求解，我们将“normal”与“potholes”图像文件置于“DATA”文件下的“normal”及“potholes”文件夹中，作为二分类的数据集。该处理我们使用Python的os及shutil库进行处理，首先指定根目录为“DATA”，再在其下创建“normal”与“potholes”文件夹，之后读取“DATA”文件夹下的所有文件，若文件名中含有“normal”字符，则将其放置于“normal”文件夹中，否则放置于“potholes”文件夹中。具体处理代码见\textbf{附录-D.1，Data Preprocessing 数据预处理}。
	
	至此，我们已将所有数据进行了人为再分类，并将数据集分别放于“normal”及"potholes"文件夹中，方便后续的处理。
	\subsection{正常与坑洼道路的比较分析、图像特征提取}
	为了方便后续模型的分析、建立与求解，我们还需要对图像数据进行机理分析，将标记为正常及坑洼的道路进行比较分析，并提取图像的特征。因此，我们从以下几个方面进行分析：
	\begin{itemize}
		\item \textbf{原图、热力图对比}：分析坑洼与正常道路的表层区别。
		\item \textbf{RGB、灰度直方图}：分析坑洼与正常道路的图像信息分布。
		\item \textbf{边缘、轮廓检测}：分析坑洼与正常道路的边缘、轮廓特征。
		\item \textbf{阈值分割}：分析坑洼与正常道路的阈值分割特征。
	\end{itemize}
	
	但由于图片较多，故我们选择“normal133.jpg”及“potholes1.jpg”进行对比分析。以下是具体分析内容，该部分具体处理代码见\textbf{附录-D.2，Comparative Analysis Of Normal And Potholes 正常与坑洼道路的比较分析}。
	\subsubsection{原图、热力图对比}
	“normal133.jpg”及“potholes1.jpg”原图及热力图对比，如\textcolor{blue}{\cref{fig:原图对比}}及\textcolor{blue}{\cref{fig:热力图对比}}所示。
	\begin{figure}[H]
		\centering
			\centering
			\includegraphics[scale=0.95]{[原图对比]normal133与potholes1.pdf}
			\caption{原图对比}
			\label{fig:原图对比}
	\end{figure}
	
	对比正常道路和坑洼道路的热力图，我们发现若整个道路的状况相同，没有坑洼，则那一片区域的热力值近似相同，热力图呈现的颜色相仿；若道路中的某一块状况与周围不同，如出现坑洼，则出现坑洼的区域热力值发生变化，使在热力图中呈现的颜色与周围存在差异。正常道路热力值基本一致，其热力图呈现色彩差别小，而坑洼道路中非坑洼处与坑洼处热力值相差较大，坑洼处与非坑洼处颜色相比存在较大差异。
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.5]{normal133热力图.pdf}
		\hspace{0.3in}
		\includegraphics[scale=0.5]{potholes1热力图.pdf}
		\caption{热力图对比}
		\label{fig:热力图对比}
	\end{figure}

	\subsubsection{RGB、灰度直方图}
	“normal133.jpg”及“potholes1.jpg”RGB及灰度直方图对比，如\textcolor{blue}{\cref{fig:RGB对比}}及\textcolor{blue}{\cref{fig:灰度对比}}所示。
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.5]{normal133RGB直方图.pdf}
		\hspace{0.3in}
		\includegraphics[scale=0.5]{potholes1RGB直方图.pdf}
		\caption{RGB直方图对比}
		\label{fig:RGB对比}
	\end{figure}
	观察RGB直方图的对比，我们可以发现两者RGB三色整体变化具有一致性，但正常道路的RGB数值整体高于坑洼道路，且正常道路RGB峰值出现在像素值为$50\text{\textasciitilde}100$之间，而坑洼道路的RGB峰值出现在像素值为$0$与$250$处。

	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.5]{normal133灰度直方图.pdf}
		\hspace{0.3in}
		\includegraphics[scale=0.5]{potholes1灰度直方图.pdf}
		\caption{灰度直方图对比}
		\label{fig:灰度对比}
	\end{figure}
	观察灰度直方图的对比，我们可先发现灰度直方图中正常道路所呈现的峰值远高于坑洼道路，其中坑洼道路的峰值出现在图像两侧，而正常道路的峰值出现在图像的中心位置。此外正常道路数值波动明显大于坑洼道路。故我们认为灰度直方图所展现的数值大小、分布及波动情况可以较好体现道路的坑洼情况。

	\subsubsection{边缘、轮廓检测}
	“normal133.jpg”及“potholes1.jpg”边缘、轮廓检测对比，如\textcolor{blue}{\cref{fig:边缘检测}}及\textcolor{blue}{\cref{fig:轮廓检测}}所示。
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.5]{normal133边缘检测.pdf}
		\hspace{0.3in}
		\includegraphics[scale=0.45]{potholes1边缘检测.pdf}
		\caption{边缘检测}
		\label{fig:边缘检测}
	\end{figure}
	观察边缘检测的对比，我们可以发现边缘检测后正常道路色彩连续完整，而坑洼道路的坑洼部分在边缘检测后整体呈现深度黑色，与平整的砂石路面形成了强烈对比。故我们认为采用边缘检测可以较好判断道路状况。

	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.58]{normal133轮廓检测.pdf}
		\hspace{0.3in}
		\includegraphics[scale=0.5]{potholes1轮廓检测.pdf}
		\caption{轮廓检测}
		\label{fig:轮廓检测}
	\end{figure}
	对道路的图片进行轮廓检测后，我们可以发现检测后无坑洼道路的图片颜色相同，而对于坑洼道路，图片上有很明显的颜色差别。经过分析，我们认为不同的颜色代表了道路的平整与坑洼，进行轮廓检测后，可以通过道路颜色的异同判断道路是否坑洼。

	\subsubsection{阈值分割}
	“normal133.jpg”及“potholes1.jpg”阈值分割对比，如\textcolor{blue}{\cref{fig:阈值分割}}所示。
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.5]{normal133阈值分割.pdf}
		\hspace{0.3in}
		\includegraphics[scale=0.42]{potholes1阈值分割.pdf}
		\caption{阈值分割}
		\label{fig:阈值分割}
	\end{figure}
	阈值分割将图片分为两类区域，对比正常道路与坑洼道路的阈值分割图，正常道路由于整个道路的状态相同，因此经阈值分割后，全部被划分为同一类，故颜色相同；而对于坑洼道路，道路中出现了与周围状态不同的区域，经过阈值分割后，呈现出不同的颜色，黑色为正常的道路，白色为道路中存在的坑洼，色彩对比强烈。

	\subsection{图像数据预处理}
	\subsubsection{opencv读取图像文件}
	考虑到图像文件较多，为方便后续处理，我们利用Python的opencv及os库，将数据加载至内存中。并分析各类中包含的图像数据个数，如\textcolor{blue}{\cref{tab:数据信息}}所示。这里罗列了原数据集与经过\textcolor{blue}{\nameref{图像文件预处理}}部分处理后的情况，同时还计算初正常道路与坑洼道路数据个数的比值。

\begin{table}[H]
	\centering
	\caption{数据信息}
	\scalebox{0.9}{
	  \begin{tabular}{ccccc}
	  \toprule
	  \textbf{类别} & \textbf{1：正常道路} & \textbf{0：坑洼道路} & \textbf{正常道路与坑洼道路图像数据个数比值} & \textbf{合计} \\
	  \midrule
	  原数据图像个数 & 266   & 35    & 7.60  & 301 \\
	  处理后图像个数 & 259   & 41    & 6.32  & 300 \\
	  \bottomrule
	  \end{tabular}}
	\label{tab:数据信息}
\end{table}
	
	\subsubsection{图像数据两类平衡化}
	我们需要重点关注\textcolor{blue}{\cref{tab:数据信息}}中正常道路与坑洼道路数据个数的比值，发现正常道路图像个数为坑洼道路图像个数的6.32倍，这意味着正常道路图像数据的数量远大于坑洼道路图像数据的数量，即对于该二分类，其数据是不平衡的，这将会对后续模型的建立与求解造成一定的影响，易造成模型的偏向性学习。因此我们需要对现有的数据进行平衡化。即尽量使得正常道路图像数据与坑洼道路图像数据的数量相近，从而使得模型的学习均衡，减少模型的偏向性。

	该处我们采用的方法是对数据集拓充，拓充的图为原数据集中尚未出现过的图像，新图像数据来源于\url{https://www.kaggle.com/}及\url{https://github.com/}。即原数据集为新数据集的子集。具体数据见\textcolor{blue}{\cref{tab:新旧数据集}}。

\begin{table}[htbp]
	\centering
	\caption{新旧数据集信息}
	\scalebox{0.9}{
	  \begin{tabular}{ccccc}
	  \toprule
			& \textbf{1：normal} & \textbf{0：potholes} & \textbf{正常道路与坑洼道路图像数据个数比值} & \textbf{总计} \\
	  \midrule
	  经预处理的数据集 & 259   & 41    & 6.32  & 300 \\
	  新数据集  & 352   & 329   & 1.07  & 681 \\
	  \bottomrule
	  \end{tabular}}
	\label{tab:新旧数据集}
\end{table}
	这里，我们将随机选择10张图像进行展示，如\textcolor{blue}{\cref{fig:新旧数据集图像}}所示。
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.5]{CNN训练样本.pdf}
		\caption{新旧数据集图像}
		\label{fig:新旧数据集图像}
	\end{figure}
	\subsubsection{划分训练集与测试集}
	对于模型的学习，我们需要对数据集进行划分，划分为训练集与测试集。训练集用于模型的训练，测试集用于对模型性能的评估分析，检验模型效果。由于该数据集样本较少，我们设置训练集占比为$80\,\%$，测试集占比为$20\,\%$，且上述划分为采用Python的sklearn库中model\_selection.train\_test\_split方法及自定义地客观地随机划分。

	\subsubsection{训练集数据增强}
	观察数据集，发现其特征多数存在相似性；同时，数据集样本较少。因此，为避免模型的过拟合与欠拟合，这里我们需要对训练集进行数据增强\textcolor{blue}{\footnote{\textbf{注意：}这里数据增强是在划分训练集与测试集之后的，并且仅对训练集数据进行增强，并不对测试集进行划分。这是由于，若在划分训练集与测试集之前进行增强，则会造成数据泄露，影响模型的准确性，以及对未知数据的泛化能力}}。从而增强模型对于未知数据集的泛化能力，提升模型的稳健性。

	这里，我们选用线性滤波中的\textbf{高斯滤波（Gauss Blur）}、非线性滤波中的\textbf{双边滤波（Bilateral Blur）}、以及对图像进行\textbf{顺时针旋转$\boldsymbol{\frac{\pi}{6}}$}处理。
	\begin{itemize}
		\item \textbf{高斯滤波}是一种线性平滑滤波。其基本原理是使用高斯核对图像进行卷积操作，进行加权平均的过程。每一个像素点的值，都由其邻域内的其他像素值和本身经过加权平均后得到。高斯核的标准差和大小决定了滤波器的效果，标准差越小，滤波器的效果越不明显，但是不会导致图像的细节信息丢失。其权值随着距离中心像素点的距离增加而逐渐减小，从而保留了图像的边缘信息。使用公式如下：
		\begin{eqnarray}
			G\left(X,Y\right)=\frac{1}{2\pi\sigma^2}\exp\left(-\frac{X^2+Y^2}{2\sigma^2}\right)
		\end{eqnarray}
		\item \textbf{双边滤波}是一种基于高斯滤波的非线性滤波方法，目的是解决高斯滤波造成的边缘模糊。结合图像的空间邻近度和像素值相似度，同时考虑空域信息和灰度相似性，实现保边去噪。双边滤波器比高斯滤波多一个高斯核。它是基于像素颜色分布的高斯滤波函数，所以在边缘附近，当两个像素距离很近时，只有同时当颜色很接近时影响才会较大，反之，虽然距离很近，但颜色差距较大，那么平滑权重也会很小。
		
		为实现双边滤波，我们首先定义滤波器的参数，即空间域核函数和像素值域核函数；然后计算出每个像素在空间域和像素值域上的权重；最后根据计算得到的权重，对每个像素的周围像素进行加权平均，以得到滤波后的像素值。其公式可表示为：
		\begin{eqnarray}
			I_f\left( X,Y \right) =\frac{1}{G\left( X,Y \right)}\sum_{\left( i,j \right) \in \Omega}{I\left( X+i,Y+j \right) \cdot F_s\left( i,j \right)}\cdot F_f\left[ I\left( X,Y \right) ,I\left( X+i,Y+j \right) \right] 
		\end{eqnarray}
		上式中各参量含义如下：
		\begin{itemize}
			\item $I_f\left(X,Y\right)$：滤波后的图像像素值；
			\item $I\left(X,Y\right)$：原始图像像素值；
			\item $G\left(X,Y\right)$：归一化权重；
			\item $\Omega$：滤波邻域窗口；
			\item $F_s\left(i,j\right)$：空间域核函数；
			\item $F_f\left[ I\left( X,Y \right) ,I\left( X+i,Y+j \right) \right]$：像素值域核函数。
		\end{itemize}
	\end{itemize}

	这里，我们随机选择一张图片，将其经过上述处理后的图像一一展示，如\textcolor{blue}{\cref{fig:原图高斯双边滤波及旋转对比}}所示。
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.6]{原图高斯双边滤波及旋转对比.pdf}
		\caption{原图、高斯滤波、双边滤波、顺时针旋转30度}
		\label{fig:原图高斯双边滤波及旋转对比}
	\end{figure}

	经过上述滤波及旋转处理后，意味着将训练集增加3倍，即现有训练集为$681\times 0.8\times 4=2179$张图像。这里，我们将随机选择10张图像进行展示，如\textcolor{blue}{\cref{fig:数据增强}}所示。
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.6]{PCA-SVM训练样本.pdf}
		\caption{数据增强图像}
		\label{fig:数据增强}
	\end{figure}

	至此，模型的数据前期准备已经完成。
	\subsection{分类模型的建立}
	\subsubsection{基于主成分分析降维、网格调优的支持向量机}
	\subsubsection{深度学习：CNN卷积神经网络}
	\subsubsection{CNN-SVM的分类模型}
	\subsection{模型的评估}
	为更好地评估模型，我们针对上述三种模型进行多维度评估，并针对各模型进行针对性分析。这里我们用到的有：
	\subsubsection{三种模型的效果逐一分析}
	% \subsubsection{基于主成分分析降维、网格调优的SVM支持向量机}
	% \subsubsection{深度学习：CNN卷积神经网络}
	% \subsubsection{CNN-SVM的分类模型}
	\subsubsection{模型对比}
	\subsection{未知数据集的预测}
	\section{模型的评价与推广}
	\subsection{模型的评价}
	\subsection{模型的推广}
	\newpage
	
	\phantomsection
	\addcontentsline{toc}{section}{\textbf{参考文献}}
	\begin{spacing}{1.08}
	\begin{thebibliography}{99}
	\bibitem{曹江华}曹江华. 复杂背景下非结构化道路可行驶区域检测研究[D].浙江科技学院,2021.

	\bibitem{pstandard}CSDN.【数据预处理】sklearn实现数据预处理（归一化、标准化）[EB/OL].
	
	\url{https://blog.csdn.net/weixin_44109827/article/details/124786873}.


	\bibitem{ppearson}王殿武,赵云斌,尚丽英,王凤刚,张震.皮尔逊相关系数算法在B油田优选化学防砂措施井的应用[J].精细与专用化学品,2022,30(07):26-28.DOI:10.19482/j.cn11-3237.2022.07.07.

	\bibitem{prf}饶雷,冉军,陶建权,胡号朋,吴沁,熊圣新.基于随机森林的海上风电机组发电机轴承异常状态监测方法[J].船舶工程,2022,44(S2):27-31.DOI:10.13788/j.cnki.cbgc.2022.S2.06.

	\bibitem{pxgboost1}陈振宇,刘金波,李晨,季晓慧,李大鹏,黄运豪,狄方春,高兴宇,徐立中.基于LSTM与XGBoost组合模型的超短期电力负荷预测[J].电网技术,2020,44(02):614-620.DOI:10.13335/j.1000-3673.pst.2019.1566.

	\bibitem{pxgboost2}杨贵军,徐雪,赵富强.基于XGBoost算法的用户评分预测模型及应用[J].数据分析与知识发现,2019,3(01):118-126.

	\bibitem{pxgboost3}Tianqi Chen and Carlos Guestrin. 2016. XGBoost: A Scalable Tree Boosting System. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '16). Association for Computing Machinery, New York, NY, USA, 785–794. \url{https://doi.org/10.1145/2939672.2939785}.

	\bibitem{pknn}张著英,黄玉龙,王翰虎.一个高效的KNN分类算法[J].计算机科学,2008(03):170-172.

	\bibitem{psvm}汪海燕,黎建辉,杨风雷.支持向量机理论及算法研究综述[J].计算机应用研究,2014,31(05):1281-1286.

	\bibitem{plightgbm}马晓君,沙靖岚,牛雪琪.基于LightGBM算法的P2P项目信用评级模型的设计及应用[J].数量经济技术经济研究,2018,35(05):144-160.DOI:10.13653/j.cnki.jqte.20180503.001.

	\bibitem{plr}唐敏,张宇浩,邓国强.高效的非交互式隐私保护逻辑回归模型[J/OL].计算机工程:1-11[2023-01-04].DOI:10.19678/j.issn.1000-3428.0065549.

	\bibitem{pstacking}史佳琪,张建华.基于多模型融合Stacking集成学习方式的负荷预测方法[J].中国电机工程学报,2019,39(14):4032-4042.DOI:10.13334/j.0258-8013.pcsee.181510.

	\bibitem{procauc}A.Tharwat, Applied Computing and Informatics (2018). \url{https://doi.org/10.1016/j.aci.2018.08.003}.
	\end{thebibliography}
	\end{spacing}
	\newpage

	\phantomsection
	\addcontentsline{toc}{section}{\textbf{附\hspace{2pc}录}}

	% \appendix
	% \ctexset{section={format={\zihao{-4}\heiti\raggedright}}}
	\begin{center}
		\heiti\zihao{4} 附\hspace{2pc}录
	\end{center}

% \phantomsection
% \addcontentsline{toc}{subsection}{[A]图示}
% 	% \section*{[A]图表}
	\noindent{\heiti [A]图示}
\newpage
% \phantomsection
% \addcontentsline{toc}{subsection}{[B]支撑文件列表}
% 	% \section*{[B]支撑文件列表}
	\noindent{\heiti [B]支撑文件列表}
	~\\

	支撑文件列表如下（列表中不包含原始数据集）：
	% Table generated by Excel2LaTeX from sheet 'Sheet2'
	\begin{table}[htbp]
	\centering
	\scalebox{0.88}{
	  \begin{tabular}{cc}
	  \toprule
	  \textbf{文件（夹）名} & \textbf{描述} \\
	  \midrule
	  附件6：result.xlsx & 用户评分预测结果 \\
	  语音业务高分组描述.csv & 语音业务高分组数据描述 \\
	  语音业务低分组描述.csv & 语音业务低分组数据描述 \\
	  上网业务高分组描述.csv & 上网业务高分组数据描述 \\
	  上网业务低分组描述.csv & 上网业务低分组数据描述 \\
	  语音业务Sample.csv & 语音业务剔除不合理评分后样本数据 \\
	  上网业务Sample.csv & 上网业务剔除不合理评分后样本数据 \\
	  语音业务词云.txt & 语音业务词云图文本内容 \\
	  上网业务词云.txt & 上网业务词云图文本内容 \\
	  词云.txt & 语音及上网业务综合词云图文本内容 \\
	  词云图.py & 语音及上网业务综合词云图代码文件 \\
	  语音业务用户分析.ipynb & 语音业务评分特征分析Jupyter文件 \\
	  上网业务用户分析.ipynb & 上网业务评分特征分析Jupyter文件 \\
	  语音业务数据分析.ipynb & 语音业务模型建立Jupyter文件 \\
	  上网业务数据分析.ipynb & 上网业务模型建立Jupyter文件 \\
	  语音业务用户分析.html & 语音业务评分特征分析运行结果 \\
	  上网业务用户分析.html & 上网业务评分特征分析运行结果 \\
	  语音业务数据分析.html & 语音业务模型建立运行结果 \\
	  上网业务数据分析.html & 上网业务模型建立运行结果 \\
	  bg.jpg & 词云底图 \\
	  wordcloud.png & 语音及上网业务综合词云图 \\
	  figuresOne & 语音业务所有图示文件夹 \\
	  figuresTwo & 上网业务所有图示文件夹 \\
	  \bottomrule
	  \end{tabular}}
  	\end{table}
  
\newpage
% \phantomsection
% \addcontentsline{toc}{subsection}{[C]使用的软件、环境}
	% \section*{[C]使用的软件、环境}
	\noindent{\heiti [C]使用的软件、环境}
	~\\

	为解决该问题，我们所使用的主要软件有：
	\begin{itemize}
		\item TeX Live 2022
		\item Visual Studio Code 1.83.1
		\item WPS Office 2023秋季更新（15398）
		\item Python 3.10.4 [MSC v.1929 64 bit (AMD64)] on win32
		\item Pycharm 2023.2.3 (Professional Edition)
	\end{itemize}
	
	Python环境下所用使用到的库及其版本如下：
\begin{table}[htbp]
	\centering
	\setlength{\aboverulesep}{0pt}
	\setlength{\belowrulesep}{0pt}
	\scalebox{0.88}{
	  \begin{tabular}{cc||cc}
	  \toprule
	  \textbf{库} & \textbf{版本} & \textbf{库} & \textbf{版本} \\
	  \midrule
	  copy  & 内置库   & missingno & 0.5.1 \\
	  jieba & 0.42.1 & mlxtend & 0.20.2 \\
	  jupyter & 1.0.0 & numpy & 1.22.4+mkl \\
	  jupyter-client & 7.3.1 & openpyxl & 3.0.10 \\
	  jupyter-console & 6.4.3 & pandas & 1.4.2 \\
	  jupyter-contrib-core & 0.4.0 & pyecharts & 1.9.1 \\
	  jupyter-contrib-nbextensions & 0.5.1 & scikit-learn & 0.22.2.post1 \\
	  jupyter-core & 4.10.0 & seaborn & 0.11.2 \\
	  jupyter-highlight-selected-word & 0.2.0 & sklearn & 0.0  \\
	  jupyterlab-pygments & 0.2.2 & snapshot\_phantomjs & 0.0.3 \\
	  jupyterlab-widgets & 1.1.0 & warnings & 内置库 \\
	  jupyter-latex-envs & 1.4.6 & wordcloud & 1.8.1 \\
	  jupyter-nbextensions-configurator & 0.5.0 & xgboost & 1.6.1 \\
	  matplotlib & 3.5.2 & yellowbrick & 1.4 \\
	  \bottomrule
	  \end{tabular}}
\end{table}

\newpage
% \phantomsection
% \addcontentsline{toc}{subsection}{[D]问题解决源程序}
	% \section*{[D]问题解决源程序}
\noindent{\heiti [D]问题解决源程序}

\textbf{D.1 Data Preprocessing 数据预处理}
\begin{python}
#!/usr/bin/env python
# coding: utf-8

# In[1]:


import os
import shutil

# 指定目录"DATA"
path = "DATA"

# 在"DATA"文件夹中创建"normal"和"potholes"文件夹
os.mkdir(os.path.join(path, "normal"))
os.mkdir(os.path.join(path, "potholes"))

# 读取"DATA"文件夹，若文件名中含有"normal"，则将其放置于"normal"文件夹中，否则放置于"potholes"文件夹中
files = os.listdir(path)
for file in files:
    if "normal" in file:
        shutil.move(os.path.join(path, file), os.path.join(path, "normal"))
    else:
        shutil.move(os.path.join(path, file), os.path.join(path, "potholes"))

\end{python}

\textbf{D.2 Comparative Analysis Of Normal And Potholes 正常与坑洼道路的比较分析}
\begin{python}
#!/usr/bin/env python
# coding: utf-8

# In[1]:


import cv2
import numpy as np
import matplotlib.pyplot as plt

# In[2]:


normalImg = cv2.imread('DATA\\normal\\normal133.jpg')
potholesImg = cv2.imread('DATA\\potholes\\potholes1.jpg')

# In[3]:


plt.rcParams['font.sans-serif'] = ['Times New Roman']
plt.rcParams['axes.unicode_minus'] = False


# In[4]:


def cv_show(img):
    b, g, r = cv2.split(img)
    img = cv2.merge([r, g, b])
    plt.imshow(img)


# In[5]:


cv_show(normalImg)

# In[6]:


cv_show(potholesImg)

# In[7]:


color = ('b', 'g', 'r')

for i, col in enumerate(color):
    histr = cv2.calcHist([normalImg], [i], None, [256], [0, 256])
    plt.plot(histr, color=col)

plt.legend(['Blue', 'Green', 'Red'])
plt.xlim([0, 256])
plt.xticks(fontsize=10)
plt.yticks(fontsize=10)
plt.title('(a) normal133.jpg', y=-0.2, fontsize=12)
plt.xlabel('Pixel Value', fontsize=11)
plt.ylabel('Number of Pixels', fontsize=11)
plt.savefig('Figures\\normal133RGB直方图.pdf', bbox_inches='tight')

# In[8]:


color = ('b', 'g', 'r')

for i, col in enumerate(color):
    histr = cv2.calcHist([potholesImg], [i], None, [256], [0, 256])
    plt.plot(histr, color=col)

plt.legend(['Blue', 'Green', 'Red'])
plt.xlim([0, 256])
plt.xticks(fontsize=10)
plt.yticks(fontsize=10)
plt.title('(b) potholes1.jpg', y=-0.2, fontsize=12)
plt.xlabel('Pixel Value', fontsize=11)
plt.ylabel('Number of Pixels', fontsize=11)
plt.savefig('Figures\\potholes1RGB直方图.pdf', bbox_inches='tight')

# In[9]:


plt.style.use('ggplot')
plt.hist(normalImg.ravel(), 256, [0, 256], color='grey')
plt.title('(a) normal133.jpg', y=-0.2, fontsize=12)
plt.xlabel('Pixel Value', fontsize=11)
plt.ylabel('Number of Pixels', fontsize=11)
plt.savefig('Figures\\normal133灰度直方图.pdf', bbox_inches='tight')

# In[10]:


plt.style.use('ggplot')
plt.hist(potholesImg.ravel(), 256, [0, 256], color='grey')
plt.title('(b) potholes1.jpg', y=-0.2, fontsize=12)
plt.xlabel('Pixel Value', fontsize=11)
plt.ylabel('Number of Pixels', fontsize=11)
plt.savefig('Figures\\potholes1灰度直方图.pdf', bbox_inches='tight')

# In[11]:


# 边缘检测
gray = cv2.cvtColor(normalImg, cv2.COLOR_BGR2GRAY)
edges = cv2.Canny(gray, 100, 200)
plt.imshow(edges, cmap='gray')
plt.title('(a) normal133.jpg', y=-0.2, fontsize=12)
plt.savefig('Figures\\normal133边缘检测.pdf', bbox_inches='tight')

# In[12]:


# 边缘检测
gray = cv2.cvtColor(potholesImg, cv2.COLOR_BGR2GRAY)
edges = cv2.Canny(gray, 100, 200)
plt.imshow(edges, cmap='gray')
plt.title('(b) potholes1.jpg', y=-0.2, fontsize=12)
plt.savefig('Figures\\potholes1边缘检测.pdf', bbox_inches='tight')

# In[13]:


plt.imshow(normalImg)
plt.colorbar()
plt.title('(a) normal133.jpg', y=-0.3, fontsize=12)
plt.savefig('Figures\\normal133热力图.pdf')

# In[14]:


plt.imshow(potholesImg)
plt.colorbar()
plt.title('(b) potholes1.jpg', y=-0.3, fontsize=12)
plt.savefig('Figures\\potholes1热力图.pdf')

# In[15]:


# 阈值分割
hsv = cv2.cvtColor(normalImg, cv2.COLOR_BGR2HSV)
lower_blue = np.array([90, 50, 50])
upper_blue = np.array([130, 255, 255])
mask = cv2.inRange(hsv, lower_blue, upper_blue)
plt.imshow(mask, cmap='gray')
plt.title('(a) normal133.jpg', y=-0.2, fontsize=12)
plt.savefig('Figures\\normal133阈值分割.pdf', bbox_inches='tight')

# In[16]:


# 阈值分割
hsv = cv2.cvtColor(potholesImg, cv2.COLOR_BGR2HSV)
lower_blue = np.array([90, 50, 50])
upper_blue = np.array([130, 255, 255])
mask = cv2.inRange(hsv, lower_blue, upper_blue)
plt.imshow(mask, cmap='gray')
plt.title('(b) potholes1.jpg', y=-0.2, fontsize=12)
plt.savefig('Figures\\potholes1阈值分割.pdf', bbox_inches='tight')

# In[17]:


# 转换为灰度图像
gray = cv2.cvtColor(normalImg, cv2.COLOR_BGR2GRAY)
# 二值化
ret, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
# 轮廓检测
contours, hierarchy = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
# 绘制轮廓
cv2.drawContours(normalImg, contours, -1, (0, 0, 255), 3)

plt.subplot(1, 2, 1)
plt.title('(a) Original', y=-0.4, fontsize=12)
plt.imshow(normalImg)
plt.subplot(1, 2, 2)
plt.imshow(binary, cmap='gray')
plt.title('(b) Contours', y=-0.4, fontsize=12)
plt.savefig('Figures\\normal133轮廓检测.pdf', bbox_inches='tight')

# In[18]:


# 转换为灰度图像
gray = cv2.cvtColor(potholesImg, cv2.COLOR_BGR2GRAY)
# 二值化
ret, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
# 轮廓检测
contours, hierarchy = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
# 绘制轮廓
cv2.drawContours(potholesImg, contours, -1, (0, 0, 255), 3)

plt.subplot(1, 2, 1)
plt.title('(a) Original', y=-0.4, fontsize=12)
plt.imshow(potholesImg)
plt.subplot(1, 2, 2)
plt.imshow(binary, cmap='gray')
plt.title('(b) Contours', y=-0.4, fontsize=12)
plt.savefig('Figures\\potholes1轮廓检测.pdf', bbox_inches='tight')

\end{python}

\textbf{D.3 Random Plot Images 随机展现正常与坑洼道路图像}
\begin{python}
#!/usr/bin/env python
# coding: utf-8

# In[1]:


import pathlib
import matplotlib.pyplot as plt
from keras.preprocessing.image import ImageDataGenerator


# In[2]:


dataDirectory = pathlib.Path('DATA\\')
classNames = [item.name for item in dataDirectory.glob('*')][:2]
classNames


# In[3]:


dataAdd = 'DATA' 
normalAdd = 'DATA\\normal'
potholesAdd = 'DATA\\potholes'

# 定义一个数据生成器，用于处理图像数据，并对数据进行归一化处理。同时，将数据集的20%作为验证数据，而其余80%用于训练
dataImageDataGenerator = ImageDataGenerator(rescale = 1/255., validation_split = 0.2)
dataTrain = dataImageDataGenerator.flow_from_directory(dataAdd, target_size = (224, 224), batch_size = 32, subset = 'training', class_mode = 'binary')
dataVal = dataImageDataGenerator.flow_from_directory(dataAdd, target_size = (224, 224), batch_size = 32, subset = 'validation', class_mode = 'binary')


# In[4]:


def random_plot_images():
    images, labels = dataTrain.next()
    labels = labels.astype('int32')
    i = 1

    plt.figure(figsize = (10, 10))
    
    for image, label in zip(images, labels):
        plt.subplot(4, 5, i)
        plt.imshow(image)
        if label == 0:
            plt.title(classNames[label],fontname='Times New Roman', fontsize=12, color='blue')
        else:
            plt.title(classNames[label],fontname='Times New Roman', fontsize=12, color='red')
        plt.axis('off')
        i += 1
        if i == 21:
            break

    plt.tight_layout()       
    plt.savefig('Figures\\图像数据观测.pdf')


random_plot_images()

\end{python}

\textbf{D.4 PCA-SVM PCA降维、网格调优的支持向量机}
\begin{python}
#!/usr/bin/env python
# coding: utf-8

# In[1]:


import os
import cv2
import numpy as np
import collections
from sklearn import svm
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.metrics import accuracy_score
from keras.preprocessing.image import ImageDataGenerator


# In[2]:


# 加载图像数据
def load_img():
    inputImg, inputLabel = [], []
    resize = (224, 224)
    for dirname, _, filenames in os.walk('DATA\\'):
        for filename in filenames:
            photo_path = os.path.join(dirname, filename)
            photo_class = dirname.split('\\')[-1]
            try:
                read_im = cv2.imread(photo_path)
                inputImg.append(cv2.resize(read_im, resize))
                # potholes == 0
                if photo_class == 'potholes':
                    inputLabel.append(0)
                # normal == 1
                elif photo_class == 'normal':
                    inputLabel.append(1)
            except:
                print(photo_path)
    return inputImg, inputLabel


inputImg, inputLabel = load_img()

# In[3]:


# 计算inputLabel中各类别的数量
counter = collections.Counter(inputLabel)
counter


# In[4]:


# 随机划分训练集和测试集，比例为test_prop，x为图像数据，y为标签
def train_test_split(test_prop, inputImg, inputLabel):
    test_size = int(np.floor(test_prop * len(inputLabel)))
    # 随机数
    np.random.seed(202310)
    test_index = np.random.choice(len(inputLabel), size=test_size, replace=False)
    # 划分
    train_x, test_x, train_y, test_y = np.delete(inputImg, test_index, axis=0), np.take(inputImg, test_index, axis=0), np.delete(inputLabel, test_index, axis=0), np.take(inputLabel, test_index, axis=0)
    # 返回图像和标签的训练集和测试集
    return train_x, test_x, train_y, test_y, test_index


train_x, test_x, train_y, test_y, test_index = train_test_split(0.2, inputImg, inputLabel)


# In[5]:


# opencv滤波增加训练集
def opencv_blur(inputImg, inputLabel):
    inputLabelNew = inputLabel.copy()
    inputImgNew = inputImg.copy()
    for i in range(len(inputImg)):
        im = inputImg[i]
        im = im.astype('uint8')
        imLbl = [inputLabel[i]]

        # 高斯滤波
        imgGaussian = cv2.GaussianBlur(im, (5, 5), 0)
        # 双边滤波
        imgBilateral = cv2.bilateralFilter(im, 9, 75, 75)

        # 添加到训练集中
        inputImgNew = np.append(inputImgNew, [imgGaussian, imgBilateral], axis=0)
        inputLabelNew = np.append(inputLabelNew, imLbl * 2, axis=0)
    return inputImgNew, inputLabelNew


inputImgNew, inputLabelNew = opencv_blur(train_x, train_y)


# In[6]:


# 图像增强，在原有的训练集上进行图像增强
def append_img(inputImg, inputLabel, imgIterator):
    inputLabelNew = inputLabel.copy()
    inputImgNew = inputImg.copy()
    for i in range(len(imgIterator)):
        im = imgIterator[i]
        im = im.astype('uint8')
        imLbl = [inputLabel[i]]
        inputImgNew = np.append(inputImgNew, im, axis=0)
        inputLabelNew = np.append(inputLabelNew, imLbl, axis=0)
    return inputImgNew, inputLabelNew


# In[7]:


# 旋转 + 30 deg
rotate_data_generartor = ImageDataGenerator(rotation_range=30)
imgIterator = rotate_data_generartor.flow(train_x, batch_size=1, shuffle=False)
inputImgNew, inputLabelNew = append_img(inputImgNew, inputLabelNew, imgIterator)

# In[8]:


# 计算inputLabelNew中各类别的数量
counter = collections.Counter(inputLabelNew)
counter


# In[9]:


def plot_img(inputImgNew, inputLabelNew):
    plt.figure(figsize=(12, 5))
    i = 1
    for image, label in zip(inputImgNew, inputLabelNew):
        if i <= 5:
            if label == 1:
                plt.subplot(2, 5, i)
                plt.imshow(image)
                plt.title('normal', fontname='Times New Roman', fontsize=12, color='blue')
                plt.axis('off')
                i += 1
        elif 5 < i < 11:
            if label == 0:
                plt.subplot(2, 5, i)
                plt.imshow(image)
                plt.title('potholes', fontname='Times New Roman', fontsize=12, color='red')
                plt.axis('off')
                i += 1
        else:
            break
    plt.savefig('Figures\\PCA-SVM训练样本.pdf', bbox_inches='tight')


plot_img(inputImgNew, inputLabelNew)

# In[10]:


nx, ny, nz = train_x.shape[1], train_x.shape[2], train_x.shape[3]
train_x_nn, test_x_nn = inputImgNew, test_x
train_x = inputImgNew.reshape((inputImgNew.shape[0], nx * ny * nz)) / 255
test_x = test_x.reshape((test_x.shape[0], nx * ny * nz)) / 255
train_y = inputLabelNew.reshape((inputLabelNew.shape[0], 1))
test_y = test_y.reshape((test_y.shape[0], 1))

# In[11]:


im_pca = PCA()
im_pca.fit(train_x)
variance_explained_list = im_pca.explained_variance_ratio_.cumsum()

# In[12]:


test_x_pca = im_pca.transform(test_x)
train_x_pca = im_pca.transform(train_x)


# In[13]:


# SVM网格调优
def svm_grid_search(C, kernel, train_x, train_y):
    accuracy_score_list = []

    for c in C:
        svmClassifier = svm.SVC(C=c, kernel=kernel)
        svmClassifier.fit(train_x, train_y.ravel())
        pred_y = svmClassifier.predict(train_x)
        accuracy = accuracy_score(train_y, pred_y)
        accuracy_score_list.append(accuracy)
        print('Regularization parameters: {:.2f}，Accuracy：{:.4f}'.format(c, accuracy))

    max_accurarcy_id = accuracy_score_list.index(max(accuracy_score_list))
    return C[max_accurarcy_id]


C, kernel = [0.1 * i for i in range(1, 30)], 'rbf'
opt_C = svm_grid_search(C, kernel, train_x_pca, train_y)

# In[14]:


svmClassifier = svm.SVC(C=opt_C, kernel='rbf')
svmClassifier.fit(train_x_pca, train_y.ravel())
pred_y = svmClassifier.predict(test_x_pca)
accuracy = accuracy_score(test_y, pred_y)
print('Test Accuracy: {:2.2f}%'.format(accuracy * 100))

# In[15]:


# 分类报告
from sklearn.metrics import classification_report

print(classification_report(test_y, pred_y))

# In[16]:


# 保存模型
import pickle

with open('Models\\PCA.pkl', 'wb') as f:
    pickle.dump(im_pca, f)
with open('Models\\PCA-SVM.pkl', 'wb') as f:
    pickle.dump(svmClassifier, f)
f.close()

\end{python}

\textbf{D.5 CNN 卷积神经网络}
\begin{python}
#!/usr/bin/env python
# coding: utf-8

# In[1]:


import os
import cv2
import h5py
import warnings
import numpy as np
import collections
import random as rn
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.utils import to_categorical
from keras.layers import Conv2D, MaxPooling2D
from sklearn.preprocessing import LabelEncoder
from keras.layers import Dense, Flatten, Dropout
from sklearn.model_selection import train_test_split

warnings.filterwarnings('always')
warnings.filterwarnings('ignore')

# In[2]:


imagePath = []
for dirname, _, filenames in os.walk('DATAX\\'):
    # 统计DATAX文件夹下子文件夹下的图片数量
    print(dirname, len(filenames))
    for filename in filenames:
        path = os.path.join(dirname, filename)
        imagePath.append(path)

len(imagePath)

# In[3]:


IMG_SIZE = 128
X = []
y = []
for image in imagePath:
    try:
        img = cv2.imread(image, cv2.IMREAD_COLOR)
        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
        X.append(np.array(img))
        if image.startswith('DATAX\\normal'):
            y.append('normal')
        else:
            y.append('potholes')
    except:
        pass

# In[4]:


fig, ax = plt.subplots(2, 5)
plt.subplots_adjust(bottom=0.3, top=0.7, hspace=0)
fig.set_size_inches(15, 12.5)

plt.rcParams['font.sans-serif'] = ['Times New Roman']
plt.rcParams['axes.unicode_minus'] = False

for i in range(2):
    for j in range(5):
        l = rn.randint(0, len(y))
        ax[i, j].imshow(X[l][:, :, ::-1])
        if y[l] == 'normal':
            ax[i, j].set_title(y[l], color='blue')
        else:
            ax[i, j].set_title(y[l], color='red')
        ax[i, j].set_aspect('equal')

plt.savefig('Figures\\CNN训练样本.pdf', bbox_inches='tight')

# In[5]:


# 统计y中各类别的数量
collections.Counter(y)

# In[6]:


le = LabelEncoder()
Y = le.fit_transform(y)
Y = to_categorical(Y, 2)
X = np.array(X)

# In[7]:


y

# In[8]:


# Y中第一列：1表示normal，0表示potholes
Y

# In[9]:


# 划分训练集和测试集，测试集占比20%
x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=5)

# In[10]:


model = Sequential()
model.add(Conv2D(32, (5, 5), activation='relu', input_shape=(128, 128, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))

model.add(Flatten())
model.add(Dropout(0.4))
model.add(Dense(128, activation='relu'))
model.add(Dense(2, activation='softmax'))

# In[11]:


model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

# In[12]:


history = model.fit(x_train, y_train, epochs=50, batch_size=12, verbose=2, validation_data=(x_test, y_test))

# In[13]:


loss, accuracy = model.evaluate(x_test, y_test)
print('Test Accuracy: {:2.2f}%'.format(accuracy * 100))

# In[14]:


plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.title('(a) Accuracy and Loss', y=-0.2)
plt.plot(history.history['accuracy'])
plt.plot(history.history['loss'])
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(['Accuracy', 'Loss'], loc='upper right')
plt.subplot(1, 2, 2)
plt.title('(b) Validation Accuracy and Loss', y=-0.2)
plt.plot(history.history['val_accuracy'])
plt.plot(history.history['val_loss'])
plt.xlabel('Epochs')
plt.ylabel('Validation Accuracy and Loss')
plt.legend(['Val Accuracy', 'Val Loss'], loc='upper left')
plt.savefig('Figures\\CNN训练结果.pdf', bbox_inches='tight')

# In[15]:


prediction = model.predict(x_test)
y_pred = np.argmax(prediction, axis=1)

# In[16]:


y_testA = y_test.astype(int)
y_testB = []
for i in y_testA:
    a = 1
    if i[0] == 1 and i[1] == 0:
        a = 0
    y_testB.append(a)

# In[17]:


# 分类报告
from sklearn.metrics import classification_report

print(classification_report(y_testB, y_pred))

# In[18]:


# 保存数据集为h5文件，包括X_train, X_test, y_train, y_test
h5f = h5py.File('Models\\CNNData.h5', 'w')
h5f.create_dataset('X_train', data=x_train)
h5f.create_dataset('X_test', data=x_test)
h5f.create_dataset('y_train', data=y_train)
h5f.create_dataset('y_test', data=y_test)
h5f.close()

# In[19]:


# 保存模型
model.save('Models\\CNN.h5')

\end{python}

\textbf{D.6 CNN-SVM 卷积神经网络与支持向量机}
\begin{python}
#!/usr/bin/env python
# coding: utf-8

# In[1]:


import h5py
from sklearn.svm import SVC
import matplotlib.pyplot as plt
from keras.models import load_model
from yellowbrick.classifier import ROCAUC
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
from yellowbrick.classifier import ConfusionMatrix
from sklearn.model_selection import cross_val_score
from yellowbrick.classifier import ClassificationReport
from yellowbrick.classifier import PrecisionRecallCurve

# In[2]:


plt.rcParams['font.sans-serif'] = ['Times New Roman']

# In[3]:


# 加载CNN模型
CNNModel = load_model('Models\\CNN.h5')

# 加载CNN数据
with h5py.File('Models\\CNNData.h5', 'r') as file:
    X_train = file['X_train'][:]
    y_train = file['y_train'][:]
    X_test = file['X_test'][:]
    y_test = file['y_test'][:]

# 使用CNN提取特征
X_train_features = CNNModel.predict(X_train)
X_test_features = CNNModel.predict(X_test)

# In[4]:


# 使用SVM分类器
svm = SVC(kernel='rbf', random_state=0, gamma=2, C=1)
svm.fit(X_train_features, y_train[:, 0])

# In[5]:


y_pred = svm.predict(X_test_features)
print('Accuracy: %.2f%%' % (accuracy_score(y_test[:, 0], y_pred) * 100))
print(classification_report(y_test[:, 0], y_pred))

# In[6]:


# 分类报告可视化
visualizer = ClassificationReport(svm, classes=['potholes', 'normal'])
visualizer.fit(X_train_features, y_train[:, 0])
visualizer.score(X_test_features, y_test[:, 0])
plt.title('CNN-SVC Classification Report')
plt.savefig('Figures\\[CNN-SVC]分类报告.pdf')

# In[7]:


# yellowbrick绘制学混淆矩阵热力图
cm = ConfusionMatrix(svm, classes=['potholes', 'normal'])
cm.fit(X_train_features, y_train[:, 0])
cm.score(X_test_features, y_test[:, 0])
plt.title('CNN-SVC Confusion Matrix')
plt.savefig('Figures\\[CNN-SVC]混淆矩阵热力图.pdf')

# In[8]:


# yellowbrick绘制ROC曲线
visualizer = ROCAUC(svm, classes=['potholes', 'normal'], binary=True)
visualizer.fit(X_train_features, y_train[:, 0])
visualizer.score(X_test_features, y_test[:, 0])
plt.legend()
plt.xlabel('False Positive Rate')
plt.ylabel('False Positive Rate')
plt.title('ROC Curves for CNN-SVC')
plt.savefig('Figures\\[CNN-SVC]ROC曲线.pdf')

# In[9]:


# yellowbrick绘制精度-召回率曲线
visualizer = PrecisionRecallCurve(svm, classes=['potholes', 'normal'])
visualizer.fit(X_train_features, y_train[:, 0])
visualizer.score(X_test_features, y_test[:, 0])
plt.legend()
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision Recall Curve for CNN-SVC')
plt.savefig('Figures\\[CNN-SVC]精确率召回率曲线.pdf')

# In[10]:


# 使用五折交叉验证
scores = cross_val_score(svm, X_test_features, y_test[:, 0], cv=5)
# 输出交叉验证分数
print(scores)
print("Accuracy: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

# In[11]:


import pickle

with open('Models\\CNN-SVM.pkl', 'wb') as f:
    pickle.dump(svm, f)
f.close()

\end{python}
\end{document}